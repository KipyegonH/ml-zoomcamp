{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "635593e9-7291-4f29-bb37-12d8a9fa79b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b49188ad-0c0e-4620-b086-22cf8980ebe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\hillarik\\Desktop\\MLzoomcamp\\Classification\\bank-full.csv\", sep=';')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee6c9685-3e93-49f2-9f89-739d43cbadaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'job', 'marital', 'education', 'default', 'balance', 'housing',\n",
       "       'loan', 'contact', 'day', 'month', 'duration', 'campaign', 'pdays',\n",
       "       'previous', 'poutcome', 'y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9028b3af-1180-4801-94ce-043eaad96b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = [\n",
    "    'age', 'job', 'marital', 'education', 'balance', 'housing', \n",
    "    'contact', 'day', 'month', 'duration', 'campaign', \n",
    "    'pdays', 'previous', 'poutcome', 'y']\n",
    "df_selected = df[columns_to_keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30e2e7f-6430-4111-8f54-238f6449157e",
   "metadata": {},
   "source": [
    "Checking Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f144a300-a825-4d5a-bee9-8bee8bdcb0d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age          0\n",
       "job          0\n",
       "marital      0\n",
       "education    0\n",
       "balance      0\n",
       "housing      0\n",
       "contact      0\n",
       "day          0\n",
       "month        0\n",
       "duration     0\n",
       "campaign     0\n",
       "pdays        0\n",
       "previous     0\n",
       "poutcome     0\n",
       "y            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_selected.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feee733f-68f9-49d1-94f4-5c4f956dbb20",
   "metadata": {},
   "source": [
    "Question one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a555a0d0-66b2-4581-b0e7-ebe32e5e98ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most frequent education: secondary\n"
     ]
    }
   ],
   "source": [
    "education_mode = df_selected['education'].mode()[0]\n",
    "print(f\"Most frequent education: {education_mode}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0899772a-00e0-4b8e-a9c9-714c2b25d81a",
   "metadata": {},
   "source": [
    "Question two-Correlation Matrix for Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "775b21b3-aa41-478a-902b-98969ea7f20d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               age   balance       day  duration  campaign     pdays  previous\n",
      "age       1.000000  0.097783 -0.009120 -0.004648  0.004760 -0.023758  0.001288\n",
      "balance   0.097783  1.000000  0.004503  0.021560 -0.014578  0.003435  0.016674\n",
      "day      -0.009120  0.004503  1.000000 -0.030206  0.162490 -0.093044 -0.051710\n",
      "duration -0.004648  0.021560 -0.030206  1.000000 -0.084570 -0.001565  0.001203\n",
      "campaign  0.004760 -0.014578  0.162490 -0.084570  1.000000 -0.088628 -0.032855\n",
      "pdays    -0.023758  0.003435 -0.093044 -0.001565 -0.088628  1.000000  0.454820\n",
      "previous  0.001288  0.016674 -0.051710  0.001203 -0.032855  0.454820  1.000000\n",
      "previous  pdays    0.45482\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "numerical_columns = ['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']\n",
    "correlation_matrix = df[numerical_columns].corr()\n",
    "print(correlation_matrix)\n",
    "highest_corr = correlation_matrix.unstack().sort_values(ascending=False)\n",
    "highest_corr = highest_corr[highest_corr != 1]\n",
    "print(highest_corr.head(1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a85412-c5ac-412f-a523-180ddb439bab",
   "metadata": {},
   "source": [
    "Target Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f12a09e-0966-42a7-8895-c4987b742872",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected.loc[:, 'y'] = df_selected['y'].map({'yes': 1, 'no': 0})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a5ff26-e9bd-409a-bd7e-b3245eb76500",
   "metadata": {},
   "source": [
    "Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aaf14d20-6747-47a9-9c9e-e5a04aba5684",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "64a8db43-c093-43e5-bfc2-9134f1506d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_selected.drop(columns=['y'])\n",
    "y = df_selected['y']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bfc93ba3-61c9-4903-8f3b-138188d43ee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27126, 9042, 9043)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = ['age', 'job', 'marital', 'education', 'balance', 'housing', 'contact', 'day', \n",
    "            'month', 'duration', 'campaign', 'pdays', 'previous', 'poutcome']\n",
    "target = 'y'\n",
    "X = df[features]   # Features (without 'y')\n",
    "y = df[target] \n",
    "df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=42)\n",
    "\n",
    "len(df_train), len(df_val), len(df_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a6ac9546-428b-4c0c-8fef-4c99ca0e2183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27126, 9042, 9043)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train), len(df_val), len(df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6c275e4b-8416-4464-98d8-539104d833b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_train = df_full_train.reset_index(drop=True)\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9005da18-a835-450f-a62e-d49228faad6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Feature  MI Score\n",
      "3   poutcome      0.03\n",
      "0    contact      0.01\n",
      "2    housing      0.01\n",
      "1  education      0.00\n",
      "The feature with the highest MI score is: poutcome\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "categorical_columns = ['contact', 'education', 'housing', 'poutcome']\n",
    "\n",
    "label_encoders = {}\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    X_train[col] = le.fit_transform(X_train[col])\n",
    "    label_encoders[col] = le  \n",
    "mi_scores = mutual_info_classif(X_train[categorical_columns], y_train, discrete_features=True)\n",
    "\n",
    "mi_scores_rounded = [round(score, 2) for score in mi_scores]\n",
    "mi_scores_rounded_df = pd.DataFrame({'Feature': categorical_columns, 'MI Score': mi_scores_rounded})\n",
    "\n",
    "mi_scores_rounded_df_sorted = mi_scores_rounded_df.sort_values(by='MI Score', ascending=False)\n",
    "print(mi_scores_rounded_df_sorted)\n",
    "most_influential_feature = mi_scores_rounded_df_sorted.iloc[0]['Feature']\n",
    "print(f'The feature with the highest MI score is: {most_influential_feature}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f451730b-1d29-4c57-a84d-559c6b6be490",
   "metadata": {},
   "source": [
    "QUESTION 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "eb262140-b895-4e3d-bc95-fb0009c06169",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "da85a8d9-0633-4794-aa40-5e822964a7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = ['job', 'marital', 'education', 'housing', 'contact', 'month', 'poutcome']\n",
    "numerical_columns = ['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "624ff3e0-9a00-4f26-a03c-90b2465916eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job - Training Unique Categories: ['blue-collar' 'technician' 'admin.' 'management' 'services' 'unemployed'\n",
      " 'housemaid' 'retired' 'entrepreneur' 'unknown' 'student' 'self-employed']\n",
      "job - Validation Unique Categories: ['blue-collar' 'technician' 'services' 'admin.' 'management'\n",
      " 'self-employed' 'retired' 'unknown' 'unemployed' 'student' 'entrepreneur'\n",
      " 'housemaid']\n",
      "\n",
      "marital - Training Unique Categories: ['married' 'single' 'divorced']\n",
      "marital - Validation Unique Categories: ['married' 'single' 'divorced']\n",
      "\n",
      "education - Training Unique Categories: [0 1 2 3]\n",
      "education - Validation Unique Categories: ['secondary' 'primary' 'tertiary' 'unknown']\n",
      "\n",
      "housing - Training Unique Categories: [1 0]\n",
      "housing - Validation Unique Categories: ['yes' 'no']\n",
      "\n",
      "contact - Training Unique Categories: [2 0 1]\n",
      "contact - Validation Unique Categories: ['cellular' 'unknown' 'telephone']\n",
      "\n",
      "month - Training Unique Categories: ['may' 'jul' 'jun' 'apr' 'aug' 'nov' 'sep' 'feb' 'oct' 'jan' 'dec' 'mar']\n",
      "month - Validation Unique Categories: ['may' 'aug' 'jul' 'jan' 'feb' 'jun' 'nov' 'apr' 'oct' 'mar' 'sep' 'dec']\n",
      "\n",
      "poutcome - Training Unique Categories: [3 2 0 1]\n",
      "poutcome - Validation Unique Categories: ['unknown' 'failure' 'success' 'other']\n",
      "\n",
      "Validation Accuracy: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hillarik\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [2, 3, 4, 6] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for column in categorical_columns:\n",
    "    print(f\"{column} - Training Unique Categories: {X_train[column].unique()}\")\n",
    "    print(f\"{column} - Validation Unique Categories: {X_val[column].unique()}\\n\")\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), categorical_columns)\n",
    "    ],\n",
    "    remainder='passthrough')\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42))])\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_pred = model.predict(X_val)\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "accuracy_rounded = round(accuracy, 2)\n",
    "print(f\"Validation Accuracy: {accuracy_rounded}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791824e7-bfad-4b15-8719-0898f30e71e8",
   "metadata": {},
   "source": [
    "QUESTION 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bb99e8-a2e7-45b0-9622-279516d73fb7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [27126, 36168]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[102], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Assuming y_train and y_val are defined and consistent with the data\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Step 3: Train the initial model with all features\u001b[39;00m\n\u001b[0;32m     18\u001b[0m model \u001b[38;5;241m=\u001b[39m LogisticRegression(solver\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m'\u001b[39m, C\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m, max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m---> 19\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_val)\n\u001b[0;32m     21\u001b[0m original_accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_val, y_pred)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1223\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1220\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1221\u001b[0m     _dtype \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32]\n\u001b[1;32m-> 1223\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1226\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1227\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1228\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1229\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mliblinear\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msag\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msaga\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1230\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1231\u001b[0m check_classification_targets(y)\n\u001b[0;32m   1232\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:650\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    648\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 650\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1320\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1301\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1302\u001b[0m     X,\n\u001b[0;32m   1303\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1315\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1316\u001b[0m )\n\u001b[0;32m   1318\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m-> 1320\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1322\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:457\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    455\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    458\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    459\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    460\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [27126, 36168]"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "# Step 1: Define the features and prepare the data\n",
    "features = ['age', 'balance', 'marital', 'previous']\n",
    "train_dict = df_train[features].to_dict(orient='records')\n",
    "val_dict = df_val[features].to_dict(orient='records')\n",
    "\n",
    "# Step 2: Vectorize the features\n",
    "dv = DictVectorizer(sparse=False)\n",
    "X_train = dv.fit_transform(train_dict)\n",
    "X_val = dv.transform(val_dict)\n",
    "\n",
    "# Assuming y_train and y_val are defined and consistent with the data\n",
    "# Step 3: Train the initial model with all features\n",
    "model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_val)\n",
    "original_accuracy = accuracy_score(y_val, y_pred)\n",
    "print('Original Accuracy:', original_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f10fbc5-91a5-4d97-a4a9-823463b2ea49",
   "metadata": {},
   "source": [
    "    QUESTION 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "be473031-9521-4018-b129-37d77cb9504e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.897\n",
      "Accuracy for C=0.1: 0.899\n",
      "Accuracy for C=1: 0.899\n",
      "Accuracy for C=10: 0.899\n",
      "Accuracy for C=100: 0.899\n",
      "Best C: 0.1 with accuracy: 0.899\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load your dataset\n",
    "# Make sure to adjust the path to where your dataset is located\n",
    "df = pd.read_csv(r\"C:\\Users\\hillarik\\Desktop\\MLzoomcamp\\Classification\\bank-full.csv\", sep=';')\n",
    "\n",
    "# Preprocess your data\n",
    "# Map target variable to binary\n",
    "df['y'] = df['y'].map({'yes': 1, 'no': 0})\n",
    "\n",
    "# Define features and target\n",
    "features = df.columns.drop('y')  # Use all columns except the target\n",
    "X = df[features]\n",
    "y = df['y']\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert categorical features to a suitable format\n",
    "dv = DictVectorizer(sparse=False)\n",
    "X_train_dict = X_train.to_dict(orient='records')\n",
    "X_val_dict = X_val.to_dict(orient='records')\n",
    "X_train_vectorized = dv.fit_transform(X_train_dict)\n",
    "X_val_vectorized = dv.transform(X_val_dict)\n",
    "\n",
    "# Regularization parameter values\n",
    "C_values = [0.01, 0.1, 1, 10, 100]\n",
    "best_accuracy = 0\n",
    "best_C = None\n",
    "\n",
    "# Iterate over C values to train the model and evaluate accuracy\n",
    "for C in C_values:\n",
    "    model = LogisticRegression(solver='liblinear', C=C, max_iter=1000, random_state=42)\n",
    "    model.fit(X_train_vectorized, y_train)\n",
    "    \n",
    "    # Predict probabilities on the validation set\n",
    "    y_pred_proba = model.predict_proba(X_val_vectorized)[:, 1]\n",
    "    \n",
    "    # Convert probabilities to binary predictions\n",
    "    y_pred = y_pred_proba >= 0.5\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = round(accuracy_score(y_val, y_pred), 3)\n",
    "    print(f'Accuracy for C={C}: {accuracy:.3f}')\n",
    "    \n",
    "    # Keep track of the best accuracy and corresponding C value\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_C = C\n",
    "\n",
    "print(f'Best C: {best_C} with accuracy: {best_accuracy:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de147c63-d9ca-4122-8b89-a72ff2599331",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
